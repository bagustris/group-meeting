# 2025-03-27 group discussions

- Bagus:  
   - AI agent/Github agent
   - APSIPA 2025 deadline: 22 June 2025

- Shun:  
    - waiting for ABCI points
    - results for lognormal distribution for segmentation  
    - create dataset for Urdu and Japanesse

- Zhou:  
    - problem in multispeaker
    - speaker and emotion are mixed 
    - try new dataset
    - try speaker disentanglement  

- Yuting:  
    - try python basic ASR  
    - try basic speech processing: mfcc, mel spectrogram 
    - diving into deep learning 

- Hu:  
    - learned github action 
    - work on cocosda web
    - deploy gpu monitor  
    - try if the method works

- Pei:  
    - prepered entrance exam (pre-submission 20 June)
    - reading related papers

- Baptiste  
    - read lot of papers 
    - run pytorch
    - did work Crema-D and IEMOCAP (past: ravdess, savee, TESS)
    - another option: solve mismatch between datasets 

- Shirai:  
    - Requested access to MELD-ST dataset
    - Propose method to measure expresiveness in source and target speech
       - via valence and arousal prediction, then calculate correlation between two  

