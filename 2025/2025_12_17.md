Hu Hongwei:    
  - presenting about flowedit paper
  - how to quantify the generate images  
  - does the middle steps important? why?


Toru Shirai:  
  - Main proposal: Humans perceive sounds based on their native language
Do self-supervised models show the same behavior?  
  - abx error any-context, results show similar trends from previous.
  - next: abx on japanese, multiphoneme recognition  


Yuting:  
  - Read recent paper di dialect speech  
  - proposed to disentangling prosodic from timbre  
  - RVC: tool to convert male to female, is it requiredi/needed?   
  - need to explain more details about how to get prosody and timbre from SSL 


Han Peichen:  
  - use r correlation coefficient, what is r here, how it could be calculated?
  - Explain the methods, not only the results
  - Try to get old man and sea dataset, and implement the same methods that have been implemented to Alice dataset  
  - How long the eeg signal corresponded to speech signal? 750 ms speech information?  

Nadim:   
  - Presentend M-AILABS MLAAD dataset, MLAAD doesn't have gender and transcription 
  - What type of approach you will used to tackle audio fake detection? 
  - Not every audio feature can be explainable, choose which are explanaible and interesting.  

Rudy Ong:  
  -  Presented work on panel detection  
  -  Ref. paper: the manga whisperer automatically 


Nguyen:  
  - Adapt how human generate lombard speech and perceive speech on noisy environment  
  - You need to show the generated speech (TTS) 
  - Mix the original LJspeech (not the output of TTS) with noise.  

Letizia:  
  - Why the performance is very low? Due to noise?
  - Compute metrics for emotion preservation  
